{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_PATH = \"E:\\\\Projects\\\\pytorch_beginner\"\n",
    "path.append(f\"{PROJECT_PATH}\\\\src\")\n",
    "DATA_PATH = f\"{PROJECT_PATH}\\\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"\"\"\n",
    "    def __init__(self, dataset, transform = None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.dataset.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        sample, y = self.dataset.data[idx], self.dataset.targets[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return (sample, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2480\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Type : torchvision.datasets.cifar.CIFAR10\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(root = DATA_PATH, train = True, download = True)\n",
    "test_data = CIFAR10(root = DATA_PATH, train = False, download = True)\n",
    "print(f\"Type : {type(train_data)}\")\n",
    "\n",
    "# composing multiple transforms into single transform\n",
    "trfms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# to apply transformation on data after loading it\n",
    "train_data = CustomDataset(dataset = train_data, transform = trfms)\n",
    "test_data = CustomDataset(dataset = test_data, transform = trfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Classes : ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_data.dataset.classes)} Classes : {train_data.dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of channels : 3, img size : torch.Size([32, 32])\n",
      "Image shape : torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "img_shape = train_data[0][0].size()\n",
    "print(f\"No. of channels : {img_shape[0]}, img size : {img_shape[1:]}\")\n",
    "print(f\"Image shape : {img_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2e9945f7550>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 4\n",
    "# transpose to change image shape from channels * height * width to height * width * channels\n",
    "plt.imshow(np.transpose(train_data[i][0].numpy(), \n",
    "                        axes = (1,2,0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/data.html\n",
    "# DataLoader supports automatically collating individual fetched\n",
    "# data samples into batches via arguments batch_size, drop_last, and batch_sampler.\n",
    "# Dataloader can be used to create fixed size batches of randomly shuffled data. \n",
    "# Note: when shuffle is set to True then every time dataloader is initialized, \n",
    "# randomly shuffle data is produced. No argument is there to set random state to \n",
    "# reproduce same batches of exactly shuffled data.\n",
    "train_loader = DataLoader(dataset = train_data, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_data, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ W_{out} = \\frac{W_{in} - F + 2P}{S} + 1 $\n",
    "\n",
    "$ W_{out} $ is output image width\n",
    "\n",
    "$ W_{in} $ is input image width\n",
    "\n",
    "$ F $ is kernel size \n",
    "\n",
    "$ P $ is padding\n",
    "\n",
    "$ S $ is stride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # calling __init__ of nn.Module\n",
    "    \n",
    "        # 3 * 32 * 32 -> 6 * 28 * 28 \n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels = 3, \n",
    "            out_channels = 6,\n",
    "            kernel_size = (5, 5))\n",
    "        \n",
    "        # 6 * 28 * 28 -> 6 * 14 * 14\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = (2, 2)) \n",
    "        \n",
    "        # 6 * 14 * 14 -> 12 * 12 * 12 -> 12 * 6 * 6\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels = 6,\n",
    "            out_channels = 12, \n",
    "            kernel_size = (3,3))\n",
    "        \n",
    "        # 12 * 6 * 6 -> 256\n",
    "        self.fc1 = nn.Linear(\n",
    "            in_features = 12 * 6 * 6, \n",
    "            out_features = 256)\n",
    "        \n",
    "        # 256 -> 128\n",
    "        self.fc2 = nn.Linear(\n",
    "            in_features = 256, \n",
    "            out_features = 128)\n",
    "        \n",
    "        # final output layer, 10 classes\n",
    "        # 128 -> 10\n",
    "        self.fc3 = nn.Linear(\n",
    "            in_features = 128, \n",
    "            out_features = 10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = self.maxpool(X)\n",
    "        X = F.relu(self.conv2(X))\n",
    "        X = self.maxpool(X)\n",
    "        X = self.flatten(X)\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = self.fc3(X)\n",
    "        return X\n",
    "        \n",
    "    def flatten(self, X):\n",
    "        size = X.size()[1:] # single data size\n",
    "        size = torch.prod(torch.tensor(size)) # flattening\n",
    "        return X.view(-1, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss :  57.17: 100%|███████████████████████████████████████████████████████████████████| 10/10 [01:09<00:00,  6.94s/it]\n"
     ]
    }
   ],
   "source": [
    "total_batches = len(train_loader)\n",
    "t = tqdm(range(NUM_EPOCHS))\n",
    "for epoch in t:\n",
    "    epoch_loss = 0.0 # to track loss over all batches\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device) \n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model.forward(x) # forward\n",
    "        loss = loss_func(y_pred, y) \n",
    "        loss.backward() # backward\n",
    "        optimizer.step() # optimize\n",
    "        \n",
    "        epoch_loss += loss.item() # accumulating loss over all batches\n",
    "        \n",
    "    t.set_description(f\"loss : {epoch_loss : .2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:00, 13.41it/s]\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "for i, batch in tqdm(enumerate(test_loader)):\n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_pred = model.forward(x)\n",
    "    y_pred = torch.argmax(y_pred, dim = 1)\n",
    "    acc.append(torch.sum(y == y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2337, device='cuda:0')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(acc) / (len(test_loader) * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_beginner",
   "language": "python",
   "name": "pytorch_beginner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
